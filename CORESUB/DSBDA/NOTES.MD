### ðŸ“Š Data Science & Big Data Analytics (DSBDA) PYQ-Based Notes

---

## ðŸ”· Q1 & Q2: Foundations of Data Science

### ðŸ“Œ Data Analytics Lifecycle

1. **Discovery**
2. **Data Preparation** (ETLT)
3. **Model Planning**
4. **Model Building**
5. **Deployment**
6. **Feedback/Iteration**

```
[Discovery] â†’ [Data Prep] â†’ [Model Planning] â†’ [Model Building] â†’ [Deploy] â†’ [Iterate]
```

### ðŸ“Œ Discovery Phase

* Identify business goal
* Understand data sources
* Define problem statement
* Stakeholder interviews

### ðŸ“Œ Data Preparation Phase (ETLT, Sandbox)

* **ETLT**: Extract, Transform, Load, Transform
* Create data sandbox for experimentation
* Remove noise, handle missing values

### ðŸ“Œ Model Planning vs Model Building

| Feature | Model Planning           | Model Building        |
| ------- | ------------------------ | --------------------- |
| Goal    | Select algorithm         | Train model with data |
| Output  | Blueprint/model strategy | Working model         |

### ðŸ“Œ BI vs Data Science

| Aspect | BI                  | Data Science            |
| ------ | ------------------- | ----------------------- |
| Goal   | Past data insights  | Predict future outcomes |
| Tool   | Dashboards, Reports | ML algorithms           |

### ðŸ“Œ Linear vs Logistic Regression

* **Linear**: Predicts continuous output (y = mx + c)
* **Logistic**: Classifies categories using sigmoid function

---

## ðŸ”· Q3 & Q4: Preprocessing & Classification

### ðŸ“Œ Handling Data Issues

* **Missing values**: Imputation, deletion
* **Transformation**: Normalization, scaling
* **Duplicates**: Removal

### ðŸ“Œ Types of Analytics

* **Descriptive**: What happened?
* **Predictive**: What might happen?
* **Diagnostic**: Why did it happen?

### ðŸ“Œ Naive Bayes Classifier

* Based on Bayes Theorem
* Assumes feature independence
* Used in spam detection, sentiment analysis

### ðŸ“Œ Logistic Regression (Sigmoid Function)

* Predicts probability between 0 and 1
* Uses sigmoid: `1 / (1 + e^-x)`

### ðŸ“Œ Decision Trees

* Tree-like model
* Nodes: attributes, branches: outcomes
* Used for both classification & regression

### ðŸ“Œ Apriori Algorithm

* Finds frequent itemsets
* Generates association rules
* Support, confidence, lift metrics

---

## ðŸ”· Q5 & Q6: Text & Cluster Analysis, Evaluation

### ðŸ“Œ K-Means Clustering

1. Choose K cluster centers
2. Assign points to nearest center
3. Recalculate centers
4. Repeat until convergence

**Euclidean Distance**: `sqrt((x2 - x1)^2 + (y2 - y1)^2)`

### ðŸ“Œ Text Processing

* **TF-IDF**: Highlights important words
* **Lemmatization**: Root word conversion
* **POS Tagging**: Grammatical tagging

### ðŸ“Œ Confusion Matrix Metrics

* **Accuracy**: (TP+TN)/(All)
* **Precision**: TP/(TP+FP)
* **Recall**: TP/(TP+FN)
* **AUC-ROC**: Measures separability

### ðŸ“Œ Validation Techniques

* **Holdout**: Split into train/test
* **K-Fold**: Data split into k subsets
* **Random Subsampling**: Random selection

---

## ðŸ”· Q7 & Q8: Visualization & Big Data Tools

### ðŸ“Œ Data Visualization Tools

* Tableau, Power BI, matplotlib, seaborn

### ðŸ“Œ Plots with Example

* **Box Plot**: Shows median, quartiles
* **Histogram**: Frequency distribution
* **Density Plot**: Smooth curve of distribution

### ðŸ“Œ Challenges

* Too much data
* Misleading visuals
* Tool limitations

### ðŸ“Œ Hadoop Ecosystem

* **HDFS**: Storage
* **MapReduce**: Batch processing model
* **Pig**: Script-based data flow
* **Hive**: SQL-like interface
* **Spark**: Fast in-memory processing

---
